{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Project\n",
    "\n",
    "## From Dummy Data to Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSession Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione per Sagemaker\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import sys,os\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, date_format, to_date, weekofyear, concat_ws, year, lit, when, row_number, length, substring, concat, expr, lpad,udf, split,concat\n",
    "from pyspark.sql.types import DateType, TimestampType, StringType, StructType, StructField, FloatType,LongType,TimestampType\n",
    "from pyspark.sql.window import Window\n",
    "import random\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "conf=SparkConf()\n",
    " \n",
    "job_name='DummyDataProjectAnalysis'\n",
    "\n",
    "#Build Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .appName(job_name) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DummyDataProjectAnalysis.parquet'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = f\"{job_name + \".parquet\"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Italian regions with longitude and Latitude\n",
    "regions_with_coords = [\n",
    "    (\"Abruzzo\", 42.3512, 13.3984),\n",
    "    (\"Basilicata\", 40.6394, 15.8055),\n",
    "    (\"Calabria\", 38.9057, 16.5948),\n",
    "    (\"Campania\", 40.8342, 14.2504),\n",
    "    (\"Emilia-Romagna\", 44.4949, 11.3426),\n",
    "    (\"Friuli Venezia Giulia\", 46.0637, 13.2376),\n",
    "    (\"Lazio\", 41.9028, 12.4964),\n",
    "    (\"Liguria\", 44.4115, 8.9327),\n",
    "    (\"Lombardia\", 45.4668, 9.1905),\n",
    "    (\"Marche\", 43.6167, 13.5189),\n",
    "    (\"Molise\", 41.5594, 14.6551),\n",
    "    (\"Piemonte\", 45.0703, 7.6869),\n",
    "    (\"Puglia\", 41.1256, 16.8666),\n",
    "    (\"Sardegna\", 40.1209, 9.0129),\n",
    "    (\"Sicilia\", 37.6000, 14.0154),\n",
    "    (\"Toscana\", 43.7711, 11.2486),\n",
    "    (\"Trentino-Alto Adige\", 46.4993, 11.3566),\n",
    "    (\"Umbria\", 43.1068, 12.3888),\n",
    "    (\"Valle d'Aosta\", 45.7373, 7.3201),\n",
    "    (\"Veneto\", 45.4408, 12.3155)\n",
    "]\n",
    "\n",
    "df_regions = spark.createDataFrame(regions_with_coords , [\"region\", \"region_latitude\",\"region_longitude\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the municipalities dataframe\n",
    "\n",
    "municipalities_with_coords = {\n",
    "    \"Abruzzo\": [\n",
    "        (\"L'Aquila\", 42.3499, 13.3995),\n",
    "        (\"Pescara\", 42.4643, 14.2142),\n",
    "        (\"Chieti\", 42.3512, 14.1675),\n",
    "        (\"Teramo\", 42.6612, 13.6984),\n",
    "        (\"Sulmona\", 42.0484, 13.9273)\n",
    "    ],\n",
    "    \"Basilicata\": [\n",
    "        (\"Potenza\", 40.6395, 15.8052),\n",
    "        (\"Matera\", 40.6698, 16.6046),\n",
    "        (\"Melfi\", 40.9981, 15.6524),\n",
    "        (\"Policoro\", 40.2109, 16.6687),\n",
    "        (\"Pisticci\", 40.3844, 16.4889)\n",
    "    ],\n",
    "    \"Calabria\": [\n",
    "        (\"Reggio Calabria\", 38.1105, 15.6613),\n",
    "        (\"Catanzaro\", 38.9106, 16.5877),\n",
    "        (\"Cosenza\", 39.3088, 16.2535),\n",
    "        (\"Lamezia Terme\", 38.9633, 16.3081),\n",
    "        (\"Vibo Valentia\", 38.6764, 16.1002)\n",
    "    ],\n",
    "    \"Campania\": [\n",
    "        (\"Naples\", 40.8518, 14.2681),\n",
    "        (\"Salerno\", 40.6824, 14.7681),\n",
    "        (\"Caserta\", 41.0747, 14.3313),\n",
    "        (\"Benevento\", 41.1291, 14.7829),\n",
    "        (\"Avellino\", 40.9142, 14.7933)\n",
    "    ],\n",
    "    \"Emilia-Romagna\": [\n",
    "        (\"Bologna\", 44.4949, 11.3426),\n",
    "        (\"Modena\", 44.6471, 10.9252),\n",
    "        (\"Parma\", 44.8015, 10.3279),\n",
    "        (\"Reggio Emilia\", 44.6989, 10.6298),\n",
    "        (\"Rimini\", 44.0678, 12.5695)\n",
    "    ],\n",
    "    \"Friuli Venezia Giulia\": [\n",
    "        (\"Trieste\", 45.6495, 13.7768),\n",
    "        (\"Udine\", 46.0656, 13.2354),\n",
    "        (\"Pordenone\", 45.9560, 12.6564),\n",
    "        (\"Gorizia\", 45.9406, 13.6207),\n",
    "        (\"Monfalcone\", 45.8095, 13.5336)\n",
    "    ],\n",
    "    \"Lazio\": [\n",
    "        (\"Rome\", 41.9028, 12.4964),\n",
    "        (\"Latina\", 41.4676, 12.9037),\n",
    "        (\"Frosinone\", 41.6412, 13.3514),\n",
    "        (\"Viterbo\", 42.4165, 12.1077),\n",
    "        (\"Rieti\", 42.4026, 12.8616)\n",
    "    ],\n",
    "    \"Liguria\": [\n",
    "        (\"Genoa\", 44.4115, 8.9327),\n",
    "        (\"La Spezia\", 44.1025, 9.8241),\n",
    "        (\"Savona\", 44.3091, 8.4771),\n",
    "        (\"Imperia\", 43.8897, 8.0395),\n",
    "        (\"Sanremo\", 43.8170, 7.7774)\n",
    "    ],\n",
    "    \"Lombardia\": [\n",
    "        (\"Milan\", 45.4668, 9.1905),\n",
    "        (\"Bergamo\", 45.6983, 9.6773),\n",
    "        (\"Brescia\", 45.5416, 10.2118),\n",
    "        (\"Como\", 45.8081, 9.0852),\n",
    "        (\"Monza\", 45.5845, 9.2744)\n",
    "    ],\n",
    "    \"Marche\": [\n",
    "        (\"Ancona\", 43.6167, 13.5189),\n",
    "        (\"Pesaro\", 43.9078, 12.9132),\n",
    "        (\"Urbino\", 43.7252, 12.6365),\n",
    "        (\"Macerata\", 43.3016, 13.4537),\n",
    "        (\"Ascoli Piceno\", 42.8619, 13.5769)\n",
    "    ],\n",
    "    \"Molise\": [\n",
    "        (\"Campobasso\", 41.5595, 14.6664),\n",
    "        (\"Isernia\", 41.5909, 14.2306),\n",
    "        (\"Termoli\", 42.0003, 14.9948),\n",
    "        (\"Venafro\", 41.4870, 14.0506),\n",
    "        (\"Bojano\", 41.4872, 14.4755)\n",
    "    ],\n",
    "    \"Piemonte\": [\n",
    "        (\"Turin\", 45.0703, 7.6869),\n",
    "        (\"Alessandria\", 44.9126, 8.6194),\n",
    "        (\"Novara\", 45.4404, 8.6212),\n",
    "        (\"Asti\", 44.8999, 8.2068),\n",
    "        (\"Cuneo\", 44.3849, 7.5422)\n",
    "    ],\n",
    "    \"Puglia\": [\n",
    "        (\"Bari\", 41.1256, 16.8666),\n",
    "        (\"Taranto\", 40.4644, 17.2470),\n",
    "        (\"Lecce\", 40.3520, 18.1696),\n",
    "        (\"Foggia\", 41.4622, 15.5446),\n",
    "        (\"Brindisi\", 40.6328, 17.9402)\n",
    "    ],\n",
    "    \"Sardegna\": [\n",
    "        (\"Cagliari\", 39.2238, 9.1217),\n",
    "        (\"Sassari\", 40.7259, 8.5550),\n",
    "        (\"Olbia\", 40.9230, 9.4867),\n",
    "        (\"Oristano\", 39.9018, 8.5916),\n",
    "        (\"Nuoro\", 40.3212, 9.3278)\n",
    "    ],\n",
    "    \"Sicilia\": [\n",
    "        (\"Palermo\", 38.1157, 13.3615),\n",
    "        (\"Catania\", 37.5079, 15.0830),\n",
    "        (\"Messina\", 38.1938, 15.5540),\n",
    "        (\"Syracuse\", 37.0755, 15.2866),\n",
    "        (\"Agrigento\", 37.3094, 13.5857)\n",
    "    ],\n",
    "    \"Toscana\": [\n",
    "        (\"Florence\", 43.7696, 11.2558),\n",
    "        (\"Pisa\", 43.7228, 10.4017),\n",
    "        (\"Siena\", 43.3188, 11.3308),\n",
    "        (\"Livorno\", 43.5485, 10.3106),\n",
    "        (\"Lucca\", 43.8424, 10.5035)\n",
    "    ],\n",
    "    \"Trentino-Alto Adige\": [\n",
    "        (\"Trento\", 46.0667, 11.1215),\n",
    "        (\"Bolzano\", 46.4983, 11.3548),\n",
    "        (\"Merano\", 46.6707, 11.1597),\n",
    "        (\"Rovereto\", 45.8919, 11.0408),\n",
    "        (\"Bressanone\", 46.7164, 11.6566)\n",
    "    ],\n",
    "    \"Umbria\": [\n",
    "        (\"Perugia\", 43.1107, 12.3908),\n",
    "        (\"Terni\", 42.5636, 12.6427),\n",
    "        (\"Foligno\", 42.9508, 12.7018),\n",
    "        (\"Spoleto\", 42.7397, 12.7340),\n",
    "        (\"Assisi\", 43.0707, 12.6196)\n",
    "    ],\n",
    "    \"Valle d'Aosta\": [\n",
    "        (\"Aosta\", 45.7373, 7.3201),\n",
    "        (\"Saint-Vincent\", 45.7520, 7.6465),\n",
    "        (\"Courmayeur\", 45.7919, 6.9653),\n",
    "        (\"Gressoney-Saint-Jean\", 45.7769, 7.8275),\n",
    "        (\"Ch√¢tillon\", 45.7450, 7.6143)\n",
    "    ],\n",
    "    \"Veneto\": [\n",
    "        (\"Venice\", 45.4408, 12.3155),\n",
    "        (\"Verona\", 45.4384, 10.9916),\n",
    "        (\"Padua\", 45.4064, 11.8768),\n",
    "        (\"Vicenza\", 45.5455, 11.5409),\n",
    "        (\"Treviso\", 45.6669, 12.2425)\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Create Municipalities df \n",
    "data = [\n",
    "    (region, municipality, mun_lat, mun_lon)\n",
    "    for region, municipalities in municipalities_with_coords.items()\n",
    "    for municipality, mun_lat, mun_lon in municipalities\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"region\", \"municipality\", \"municipality_latitude\", \"municipality_longitude\"]\n",
    "df_municipalities = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_municipalities.show(20, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Regions and Municipalities DataFrame\n",
    "\n",
    "df_geography = df_regions.join(df_municipalities, df_regions.region == df_municipalities.region) \\\n",
    "                .select(df_regions.region, df_regions.region_latitude, df_regions.region_longitude \\\n",
    "                        ,  df_municipalities.municipality, df_municipalities.municipality_latitude \\\n",
    "                        , df_municipalities.municipality_longitude) \n",
    "            \n",
    "     \n",
    "df_geography.show(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator function to produce consecutive dates.\n",
    "def generate_dates(start_date, num_days):\n",
    "    for i in range(num_days):\n",
    "        yield (start_date + timedelta(days=i)).strftime(\"%Y-%m-%d\"),\n",
    "\n",
    "# Start date\n",
    "start_date = datetime.strptime(\"2018-06-03\", \"%Y-%m-%d\")\n",
    "\n",
    "# Generate 1 million consecutive dates\n",
    "dates = generate_dates(start_date, 60)\n",
    "\n",
    "\n",
    "# Create DataFrame from the generator\n",
    "df = spark.createDataFrame(dates ,  [\"dates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Dates dataframe with Region Dataframe \n",
    "\n",
    "df = df.crossJoin(df_geography)\n",
    "\n",
    "#df.filter(df.Region == \"Basilicata\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate random time (in HH:MM:SS format)\n",
    "def generate_time():\n",
    "    return f\"{random.randint(0, 23):02d}:{random.randint(0, 59):02d}:{random.randint(0, 59):02d}\"\n",
    "\n",
    "# UDF for random time generation\n",
    "time_udf = udf(generate_time, StringType())\n",
    "\n",
    "# Function to generate random latency (in milliseconds)\n",
    "def generate_latency():\n",
    "    return random.randint(0, 100)  # Latency in milliseconds (ms)\n",
    "\n",
    "# UDF for random latency generation\n",
    "latency_udf = udf(generate_latency, IntegerType())\n",
    "\n",
    "# Function to generate random throughput (in Megabits per second, Mbps)\n",
    "def generate_throughput():\n",
    "    return random.randint(10, 1000)  # Throughput in Mbps\n",
    "\n",
    "# UDF for random throughput generation\n",
    "throughput_udf = udf(generate_throughput, IntegerType())\n",
    "\n",
    "# Function to generate random signal strength (in dBm)\n",
    "def generate_signal_strength():\n",
    "    return random.randint(-140, -44)  # Signal strength in dBm\n",
    "\n",
    "signal_strength_udf = udf(generate_signal_strength, IntegerType())\n",
    "\n",
    "# Function to generate packet loss rate (in percentage)\n",
    "def generate_packet_loss_rate():\n",
    "    return round(random.uniform(0.0, 5.0), 2)  # Packet loss rate in percentage (%)\n",
    "\n",
    "# UDF for random packet loss rate generation\n",
    "packet_loss_rate_udf = udf(generate_packet_loss_rate, FloatType())\n",
    "\n",
    "# UDF for generating random jitter (in milliseconds)\n",
    "def generate_jitter():\n",
    "    return round(random.uniform(0.0, 50.0), 2)  # Jitter in the range 0 to 50 ms\n",
    "\n",
    "jitter_udf = udf(generate_jitter, FloatType())\n",
    "\n",
    "# UDF for generating random network utilization (as a percentage)\n",
    "def generate_network_utilization():\n",
    "    return random.randint(0, 100)  # Utilization in percentage (0 to 100%)\n",
    "\n",
    "network_utilization_udf = udf(generate_network_utilization, IntegerType())\n",
    "\n",
    "# UDF for generating random data volume (in Megabytes, MB)\n",
    "def generate_data_volume():\n",
    "    return random.randint(1, 10000)  # Data volume in Megabytes (MB)\n",
    "\n",
    "volume_udf = udf(generate_data_volume, LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional columns to DataFrame\n",
    "\n",
    "df = df.withColumn(\"dates\", to_date(\"dates\"))\n",
    "df = df.withColumn(\"latency\", latency_udf())\n",
    "df = df.withColumn(\"throughput\", throughput_udf())\n",
    "df = df.withColumn(\"signal_strengh\", signal_strength_udf())\n",
    "df = df.withColumn(\"packet_loss\", packet_loss_rate_udf())\n",
    "df = df.withColumn(\"jitter\", jitter_udf())\n",
    "df = df.withColumn(\"network_utilization\", network_utilization_udf())\n",
    "df = df.withColumn(\"volume\", volume_udf())\n",
    "df = df.withColumn(\"time\", time_udf())\n",
    "df = df.withColumn(\"hour\", split(df.time, \":\").getItem(0).cast(IntegerType()))\n",
    "\n",
    "\n",
    "# Combine dates and time to create a timestamp\n",
    "df = df.withColumn(\"day_time\", concat(col(\"dates\"), lit(\" \"), col(\"time\")).cast(TimestampType()))\n",
    "\n",
    "# Drop the separate time column if not needed\n",
    "df = df.drop(\"time\")\n",
    "\n",
    "# only for check purpose\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the schema of the DataFrame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder and Show some example rows\n",
    "df= df.select( df.dates, df.day_time, df.hour, df.region, df.region_latitude, df.region_longitude \\\n",
    "              ,df.municipality, df.municipality_latitude, df.municipality_longitude \\\n",
    "              ,df.latency, df.throughput, df.signal_strengh, df.packet_loss \\\n",
    "              , df.jitter, df.network_utilization, df.volume\n",
    "             )\n",
    "# only for check purpose\n",
    "df.show(10, truncate =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema enforcement\n",
    "\n",
    "final_schema = schema = StructType([\n",
    "    StructField(\"dates\", DateType(), True),\n",
    "    StructField(\"day_time\", TimestampType(), True),\n",
    "    StructField(\"hour\", IntegerType(), True),\n",
    "    StructField(\"region\", StringType(), True),\n",
    "    StructField(\"region_latitude\", FloatType(), True),\n",
    "    StructField(\"region_longitude\", FloatType(), True),\n",
    "    StructField(\"municipality\", StringType(), True),\n",
    "    StructField(\"municipality_latitude\", FloatType(), True),\n",
    "    StructField(\"municipality_longitude\", FloatType(), True),\n",
    "    StructField(\"latency\", IntegerType(), True),\n",
    "    StructField(\"throughput\", IntegerType(), True),\n",
    "    StructField(\"signal_strength\", IntegerType(), True),\n",
    "    StructField(\"packet_loss\", FloatType(), True),\n",
    "    StructField(\"jitter\", FloatType(), True),\n",
    "    StructField(\"network_utilization\", IntegerType(), True),\n",
    "    StructField(\"volume\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(df.rdd, final_schema)\n",
    "\n",
    "# only for check purpose\n",
    "df.filter(df.region == \"Basilicata\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write \\\n",
    "    .mode(\"append\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .partitionBy(\"dates\") \\\n",
    "    .save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
